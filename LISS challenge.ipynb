{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca915d6",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc51ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split #for creating a hold-out sample\n",
    "\n",
    "import sklearn #for building models\n",
    "import sklearn.ensemble #for building models\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee68ae",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import paths\n",
    "original_data = pd.read_csv(\"datasets/LISS_example_input_data.csv\", encoding=\"cp1252\") ##encoding=\"ISO-8859-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = pd.read_csv(\"datasets/LISS_example_groundtruth_data.csv\")\n",
    "# Drop observations where the outcome is missing\n",
    "y_isna = outcome['new_child'].isnull()\n",
    "data = original_data.loc[~y_isna]\n",
    "outcome = outcome.loc[~y_isna]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ad409",
   "metadata": {},
   "source": [
    "## Select variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nas for each group\n",
    "keepcols = ['positie2019','positie2018','gebjaar', 'geslacht','aantalhh2019', 'sted2019', \n",
    "            'nettohh_f2019', 'oplmet2019', 'herkomstgroep2019', 'cf19l128','cf19l129',\n",
    "            'cf19l130', 'cf19l131','cf19l132','woning2019', 'woning2018', \n",
    "            'cf19l456', 'cf19l457', 'cf19l458', 'cf19l459', 'cw19l522', 'cr19l143', \n",
    "            'cf19l483', 'cf19l484', 'cf19l485', 'cf19l486', 'cf19l487', 'cf19l488',\n",
    "           'wave2008', 'wave2014', 'wave2019','aantalki2017','aantalki2018',\n",
    "            'partner2018','partner2019', 'belbezig2019','belbezig2018',\n",
    "           'ch19l004','ch19l014','ch19l178','ch19l219',\n",
    "            'cp19k118', 'cp19k021', 'cp19k056']#\n",
    "#keepcols=['herkomstgroep2010', 'herkomstgroep2011',\n",
    "#'herkomstgroep2012', 'herkomstgroep2013', 'herkomstgroep2014',\n",
    "#'herkomstgroep2015', 'herkomstgroep2016', 'herkomstgroep2017',\n",
    "#'herkomstgroep2018', 'herkomstgroep2019']\n",
    "\n",
    "#keepcols = ['aantalki2007','aantalki2008','aantalki2009','aantalki2010','aantalki2011','aantalki2012',\n",
    "            #'aantalki2013', 'aantalki2014', 'aantalki2015', 'aantalki2016', 'aantalki2017', \n",
    "            #'aantalki2018', 'aantalki2019']\n",
    "data2 = data.loc[:, keepcols]\n",
    "data2.isna().sum()\n",
    "#data2['ch19l178'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features from kbset\n",
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.datasets import load_iris\n",
    "#from sklearn.feature_selection import SelectFromModel\n",
    "#clf = ExtraTreesClassifier(n_estimators=50)\n",
    "#clf = clf.fit(X_train, y_train)\n",
    "#clf.feature_importances_  \n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse_output=False).set_output(transform=\"pandas\")  \n",
    "#pandas is just to set output to dataframe\n",
    "#categorical_columns_selector = selector(dtype_include=object) #create selector for columns with type \"object\"\n",
    "#categorical_columns = categorical_columns_selector(data)\n",
    "#encoder.fit_transform(data[categorical_columns]) \n",
    "\n",
    "#X, y = load_digits(return_X_y=True)\n",
    "#X_new = SelectKBest(chi2, k=20).fit_transform(data, outcome['new_child'])\n",
    "#X_new.shape\n",
    "dict_kids = {'None': 0, 'One child': 1, 'Two children': 2, 'Three children': 3, 'Four children': 4, 'Five children': 5, 'Six children': 6}\n",
    "data[\"aantalki2018\"] = data[\"aantalki2018\"].map(dict_kids)\n",
    "\n",
    "feature_test = Pipeline([\n",
    "               (\"preprocess\", preprocessor),\n",
    "               (\"classifier\", SelectKBest(chi2, k=50)) # LogisticRegression(max_iter=500)\n",
    "               ]) \n",
    "feature_test.fit(data,outcome['new_child'])\n",
    "\n",
    "#2nd way\n",
    "data.columns[feature_test['classifier'].get_support(indices=True)].tolist()\n",
    "#feature_test[\"classifier\"].get_feature_names_out()\n",
    "#feature_test[\"classifier\"].columns[selector.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705169dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features from ExtraTreesClassifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#clf = ExtraTreesClassifier(n_estimators=50)\n",
    "#clf = clf.fit(X_train, y_train)\n",
    "#clf.feature_importances_  \n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "\n",
    "#X, y = load_digits(return_X_y=True)\n",
    "#X_new = SelectKBest(chi2, k=20).fit_transform(data, outcome['new_child'])\n",
    "#X_new.shape\n",
    "dict_kids = {'None': 0, 'One child': 1, 'Two children': 2, 'Three children': 3, 'Four children': 4, 'Five children': 5, 'Six children': 6}\n",
    "data[\"aantalki2018\"] = data[\"aantalki2018\"].map(dict_kids)\n",
    "\n",
    "feature_test = Pipeline([\n",
    "               (\"preprocess\", preprocessor),\n",
    "               (\"classifier\", ExtraTreesClassifier(n_estimators=50)) # \"classifier\", SelectKBest(chi2, k=50)\n",
    "               ]) \n",
    "feature_test.fit(data,outcome['new_child'])\n",
    "\n",
    "print_sorted_importance(feature_test['classifier'].feature_importances_, data.columns)\n",
    "\n",
    "#2nd way\n",
    "#data.columns[feature_test['classifier'].get_support(indices=True)].tolist()\n",
    "#feature_test[\"classifier\"].get_feature_names_out()\n",
    "#feature_test[\"classifier\"].columns[selector.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select predictors: education, year of birth, gender, number of children in the household \n",
    "# You can do this automatically (not necessarily better): https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "keepcols = ['positie2019','positie2018','gebjaar', 'geslacht','aantalhh2019', 'sted2019', \n",
    "            'nettohh_f2019', 'oplmet2019', 'herkomstgroep2019', 'cf19l128','cf19l129',\n",
    "            'cf19l130', 'cf19l131','cf19l132','woning2019', 'woning2018', \n",
    "            'cf19l456', 'cf19l457', 'cf19l458', 'cf19l459', 'cw19l522', 'cr19l143', \n",
    "            'cf19l483', 'cf19l484', 'cf19l485', 'cf19l486', 'cf19l487', 'cf19l488',\n",
    "           'wave2008', 'wave2014', 'wave2019','aantalki2017','aantalki2018',\n",
    "            'partner2018','partner2019', 'belbezig2019','belbezig2018','ch19l178',\n",
    "           'cp19k118', 'cp19k021', 'cp19k056']\n",
    "# Took out most mental health vars b/c seemed to make model worse 'ch19l004','ch19l014','ch19l219'\n",
    "#taking out 'cr19l090','cf19l133','cf19l134', 'burgstat2019','woonvorm2019', aantalki2019 changed to 2018\n",
    "#Only keep wave 2008, 2014, 2019, top 2 predictors plus 2014 because peak\n",
    "# gebjaar = years of birth\n",
    "# geslacht = gender\n",
    "# leeftijd = age in years (redundant with gebjaar)\n",
    "# positie = household position, head, married to head, etc.\n",
    "# aantalhh = # household members\n",
    "# partner = does household head live with partner yes/no\n",
    "# burgstat = civil status (married, separated, divorced, widowed)\n",
    "# woonvorm = domestic situation (married, cohabitation w/ or w/out kids, single)\n",
    "# aantalki = # children of household head\n",
    "# woning = type of house (own, rent, etc)\n",
    "# nettohh = household income in euros\n",
    "# sted = urbannness - urban - rural\n",
    "# belbezig = occupation (paid, searching, etc)\n",
    "# oplmet = highest education acheived\n",
    "# herkomstgroep = Dutch, immigrant\n",
    "# cf19l128 = children intentions\n",
    "# cf19l129 = # children intentions\n",
    "# cf19l130 = how soon children intentions\n",
    "# cf19l131 = household help father\n",
    "# cf19l132 = household help mother\n",
    "# cf19l133 = childcare help father -- missing for ~2/3\n",
    "# cf19l134 = childcare help mother -- missing for ~2/3\n",
    "# cf19l456-cf191459 = birth year of 1st, 2nd, 3rd, 4th child, many missing (deal w/NAs below)\n",
    "# cf19l483 = equality of prepping food\n",
    "# cf19l484 = equality of laundry\n",
    "# cf19l485 = equality of house cleaning\n",
    "# cf19l486 = equality of odd jobs\n",
    "# cf19l487 = equality of finances\n",
    "# cf19l488 = equality of groceries\n",
    "# cw19l522 = unemployment\n",
    "# cr19l143 = belonging to church/religious community\n",
    "# cr19l090 = what non-dutch language is spoken at home #very few observations\n",
    "# wave gives year/month that was answered--want to change to categorical participated in the wave/did not\n",
    "# ch19l004: general health\n",
    "# ch19l014: feelings of depression\n",
    "# ch19l178: being on anti-depressant meds\n",
    "# ch19l219: seeing gynaecologist\n",
    "# cp19k118: importance of family security \n",
    "# cp19k021: feel little concern for others\n",
    "# cp19k056: take time out for others\n",
    "\n",
    "data2 = data.loc[:, keepcols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2,\n",
    "                                                    outcome,\n",
    "                                                    test_size=0.25, random_state=2023)\n",
    "y_train = y_train[\"new_child\"]\n",
    "y_test = y_test[\"new_child\"]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2f302",
   "metadata": {},
   "source": [
    "## Upsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5352dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsample data to over-represent births in training data set\n",
    "from sklearn.utils import resample\n",
    "target_upsample, data_upsample = resample(y_train[y_train == 1],\n",
    "                                          X_train[y_train == 1],\n",
    "             replace=True,\n",
    "             n_samples=int(len(y_train[y_train == 0])),\n",
    "             random_state=42)\n",
    "#add upsample to dataset\n",
    "y_train2 = pd.concat([target_upsample, y_train[y_train==0]])\n",
    "X_train2 = pd.concat([data_upsample, X_train[y_train==0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6476b67",
   "metadata": {},
   "source": [
    "# 3. Pre-process and model\n",
    "You may not want to include the preprocessing in the pipeline if it becomes too cumbersome\n",
    "\n",
    "Make sure to use the scoring that you want to optimize in the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "2df63514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positie2019             object\n",
       "positie2018             object\n",
       "gebjaar                  int64\n",
       "geslacht                object\n",
       "aantalhh2019            object\n",
       "sted2019                object\n",
       "nettohh_f2019          float64\n",
       "oplmet2019              object\n",
       "herkomstgroep2019       object\n",
       "cf19l128               float64\n",
       "cf19l129               float64\n",
       "cf19l130               float64\n",
       "cf19l131               float64\n",
       "cf19l132               float64\n",
       "woning2019              object\n",
       "woning2018              object\n",
       "cf19l456                object\n",
       "cf19l457                object\n",
       "cf19l458                object\n",
       "cf19l459                object\n",
       "cw19l522               float64\n",
       "cr19l143               float64\n",
       "cf19l483               float64\n",
       "cf19l484               float64\n",
       "cf19l485               float64\n",
       "cf19l486               float64\n",
       "cf19l487               float64\n",
       "cf19l488               float64\n",
       "wave2008                object\n",
       "wave2014                object\n",
       "wave2019                object\n",
       "aantalki2017           float64\n",
       "aantalki2018           float64\n",
       "partner2018             object\n",
       "partner2019             object\n",
       "belbezig2019            object\n",
       "belbezig2018            object\n",
       "ch19l178               float64\n",
       "cp19k118               float64\n",
       "cp19k021               float64\n",
       "cp19k056               float64\n",
       "change_kids               bool\n",
       "change_partner            bool\n",
       "change_householdPos       bool\n",
       "change_jobs               bool\n",
       "change_house              bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of a preprocessing apart from the pipeline\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Convert # children string to number\n",
    "dict_kids = {'None': 0, 'One child': 1, 'Two children': 2, 'Three children': 3, 'Four children': 4, 'Five children': 5, 'Six children': 6}\n",
    "X_train2[\"aantalki2018\"] = X_train2[\"aantalki2018\"].map(dict_kids)\n",
    "X_train2[\"aantalki2017\"] = X_train2[\"aantalki2017\"].map(dict_kids)\n",
    "#2019 --> 2018\n",
    "\n",
    "#Convert wave number to string, code NAs\n",
    "#wave_cols = ['wave2007', 'wave2008', 'wave2009', 'wave2010', 'wave2011', 'wave2012', \n",
    "#             'wave2013', 'wave2014', 'wave2015', 'wave2016', 'wave2017', 'wave2018', 'wave2019']\n",
    "wave_cols = ['wave2008', 'wave2014', 'wave2019']#\n",
    "X_train2[wave_cols] = X_train2[wave_cols].fillna(0)\n",
    "X_train2[wave_cols] = X_train2[wave_cols].astype('object')\n",
    "\n",
    "#Create new variables about changes in partner status or number of kids (indicators)\n",
    "X_train2['change_kids'] = (X_train2['aantalki2018'].fillna(-1) != X_train2['aantalki2017'].fillna(-1)) & (~X_train2['aantalki2018'].isna()) & (~X_train2['aantalki2017'].isna())\n",
    "#Change in partner status\n",
    "X_train2['change_partner'] = (X_train2['partner2019'].fillna(-1) != X_train2['partner2018'].fillna(-1)) & (~X_train2['partner2019'].isna()) & (~X_train2['partner2018'].isna())\n",
    "#Change in household position\n",
    "X_train2['change_householdPos'] = (X_train2['positie2019'].fillna(-1) != X_train2['positie2018'].fillna(-1)) & (~X_train2['positie2019'].isna()) & (~X_train2['positie2018'].isna())\n",
    "#Change in employment\n",
    "X_train2['change_jobs'] = (X_train2['belbezig2019'].fillna(-1) != X_train2['belbezig2018'].fillna(-1)) & (~X_train2['belbezig2019'].isna()) & (~X_train2['belbezig2018'].isna())\n",
    "#Change in housing\n",
    "X_train2['change_house'] = (X_train2['woning2019'].fillna(-1) != X_train2['woning2018'].fillna(-1)) & (~X_train2['woning2019'].isna()) & (~X_train2['woning2018'].isna())\n",
    "\n",
    "# make sure missing child birth age is filled with different value\n",
    "child_cols = ['cf19l456', 'cf19l457','cf19l458','cf19l459']\n",
    "X_train2[child_cols] = X_train2[child_cols].fillna(0)\n",
    "X_train2[child_cols] = X_train2[child_cols].astype('object')\n",
    "\n",
    "\n",
    "#Suggests that this might lead to a lot of debugging (not sure of alternatives though)\n",
    "# Create transformers\n",
    "\n",
    "#import sklearn_pandas\n",
    "#from sklearn_pandas import CategoricalImputer\n",
    "#>>> data = np.array(['a', 'b', 'b', np.nan], dtype=object)\n",
    "#>>> imputer = CategoricalImputer()\n",
    "#>>> imputer.fit_transform(data)\n",
    "#array(['a', 'b', 'b', 'b'], dtype=object)\n",
    "# Imputer are sometimes not necessary\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), #applies most frequent category, not ideal #SimpleImputer(strategy='most_frequent')\n",
    "    ('encoder', OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=50))]) \n",
    "#put variables with too few observations in separate category\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=100)), #mean is not ideal, impute based on other vars #SimpleImputer(strategy=\"mean\")\n",
    "    ('scaler', StandardScaler())])#MinMaxScaler()\n",
    "\n",
    "#data[\"Age\"] = data[\"Age\"].interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "\n",
    "# Use ColumnTransformer to apply the transformations to the correct columns in the dataframe\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, selector(dtype_exclude=object)(X_train2)),\n",
    "        ('cat', categorical_transformer, selector(dtype_include=object)(X_train2))])\n",
    "\n",
    "#X_train2.head(n=10)\n",
    "#X_train2['change_jobs'].value_counts()\n",
    "X_train2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create pipeline\n",
    "model = Pipeline([\n",
    "               (\"preprocess\", preprocessor),\n",
    "               (  #GradientBoostingClassifier(n_estimators=1000, subsample=0.75, max_depth=7)) \n",
    "                   # LogisticRegression(max_iter=500)\n",
    "                   \"classifier\", GradientBoostingClassifier(n_estimators=1000, subsample=0.75, max_depth=7, learning_rate=0.5))\n",
    "                   #\"classifier\", HistGradientBoostingClassifier(max_iter=1000, max_depth=3, learning_rate=0.8))\n",
    "               ]) \n",
    "                      \n",
    "# Define the hyperparameters, this can include several classifiers, but will make it slow\n",
    "# You can see different classifiers here: \n",
    "# https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "#Logistic regression has values that will allow for more or less regularization (min parameters)\n",
    "parameters = [\n",
    "    { #'classifier': [HistGradientBoostingClassifier(max_iter=1000), GradientBoostingClassifier(n_estimators=1000, subsample=0.75)],\n",
    "        'classifier': [GradientBoostingClassifier(n_estimators=1000, subsample=0.75, max_depth=7, learning_rate=0.5)], \n",
    "        #'classifier': [RandomForestClassifier()],\n",
    "     #'classifier__learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "     #'classifier__max_depth': [3, 5, 7, 9]\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# to search over parameters 'classifier__C': np.logspace(-3, 3, 50) #regularization coefficient\n",
    "\n",
    "# Perform hyperparameter tuning using cross-validation: https://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers\n",
    "# Scoring metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# f1 = f1 of the class labeled as 1 (i.e. kids)\n",
    "grid_search = GridSearchCV(model, parameters, cv=5, n_jobs=-1, scoring=\"f1\", verbose=9) #n_jobs=-1 allows for multiprocessing\n",
    "grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "# Keep best model (or define it from scratch with the best coefficients found)\n",
    "best_model = grid_search.best_estimator_\n",
    "#model.fit(X_train2, y_train2)\n",
    "#best_model = model\n",
    "best_model\n",
    "\n",
    "#First iteration: learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.75\n",
    "#Second iteration (only learning rate, max_depth): learning_rate = 0.2, max_depth = 7\n",
    "#third iteration (only learning rate): learning_rate = 0.5, I think too high and will stick with default of 0.1\n",
    "#new test comparing gradient and histgradient on learning rate and max depth always seems to give gradient\n",
    "#some instability in parameters, but max_depth 7-9, and learning rate 0.1 -0.9?\n",
    "#just optimizing on learning rate gives learning rate = 0.4\n",
    "#Gives best C (complexity/regularization parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable names in the data\n",
    "#best_model\n",
    "best_model[\"preprocess\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4382e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sorted_importance(importances, columns, codebook=None):\n",
    "    for imp, var in sorted(zip(importances, columns))[::-1]:\n",
    "        if codebook is not None:\n",
    "            print(f\"{imp:2.3f}: {codebook[var]:50.50s}\")\n",
    "        else:\n",
    "            print(f\"{imp:2.3f}: {var:50.50s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea101441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance (not sure exactly what it does under the hood)\n",
    "# GBT from scikit-learn\n",
    "print_sorted_importance(best_model['classifier'].feature_importances_, X_train2.columns)#, codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa994f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"aantalki2018\"] = X_test[\"aantalki2018\"].map(dict_kids)\n",
    "X_test[\"aantalki2017\"] = X_test[\"aantalki2017\"].map(dict_kids)\n",
    "#Create new variables about changes in partner status or number of kids (indicators)\n",
    "X_test['change_kids'] = (X_test['aantalki2018'].fillna(-1) != X_test['aantalki2017'].fillna(-1)) & (~X_test['aantalki2018'].isna()) & (~X_test['aantalki2017'].isna())\n",
    "#Change partner status\n",
    "X_test['change_partner'] = (X_test['partner2019'].fillna(-1) != X_test['partner2018'].fillna(-1)) & (~X_test['partner2019'].isna()) & (~X_test['partner2018'].isna())\n",
    "#Change in household position\n",
    "X_test['change_householdPos'] = (X_test['positie2019'].fillna(-1) != X_test['positie2018'].fillna(-1)) & (~X_test['positie2019'].isna()) & (~X_test['positie2018'].isna())\n",
    "#Change in employment\n",
    "X_test['change_jobs'] = (X_test['belbezig2019'].fillna(-1) != X_test['belbezig2018'].fillna(-1)) & (~X_test['belbezig2019'].isna()) & (~X_test['belbezig2018'].isna())\n",
    "#Change in housing\n",
    "X_test['change_house'] = (X_test['woning2019'].fillna(-1) != X_test['woning2018'].fillna(-1)) & (~X_test['woning2019'].isna()) & (~X_test['woning2018'].isna())\n",
    "\n",
    "wave_cols = ['wave2008', 'wave2014', 'wave2019']#\n",
    "X_test[wave_cols] = X_test[wave_cols].fillna(0)\n",
    "X_test[wave_cols] = X_test[wave_cols].astype('object')\n",
    "\n",
    "# make sure missing child birth age is filled with different value\n",
    "child_cols = ['cf19l456', 'cf19l457','cf19l458','cf19l459']\n",
    "X_test[child_cols] = X_test[child_cols].fillna(0)\n",
    "X_test[child_cols] = X_test[child_cols].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60496ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance (how worse does model get without variable?)\n",
    "\n",
    "#Feature importance via permutation\n",
    "X_test[\"aantalki2018\"] = X_test[\"aantalki2018\"].map(dict_kids)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(best_model, X_test, y_test,\n",
    "                            n_repeats=30,\n",
    "                            random_state=0)\n",
    "\n",
    "print_sorted_importance(r[\"importances_mean\"], X_train2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd757ca",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "\n",
    "Note: The results below are not for LogisticRegression, are for a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"aantalki2018\"] = X_test[\"aantalki2018\"].map(dict_kids)\n",
    "X_test[\"aantalki2017\"] = X_test[\"aantalki2017\"].map(dict_kids)\n",
    "#Create new variables about changes in partner status or number of kids (indicators)\n",
    "X_test['change_kids'] = (X_test['aantalki2018'].fillna(-1) != X_test['aantalki2017'].fillna(-1)) & (~X_test['aantalki2018'].isna()) & (~X_test['aantalki2017'].isna())\n",
    "#Change partner status\n",
    "X_test['change_partner'] = (X_test['partner2019'].fillna(-1) != X_test['partner2018'].fillna(-1)) & (~X_test['partner2019'].isna()) & (~X_test['partner2018'].isna())\n",
    "#Change in household position\n",
    "X_test['change_householdPos'] = (X_test['positie2019'].fillna(-1) != X_test['positie2018'].fillna(-1)) & (~X_test['positie2019'].isna()) & (~X_test['positie2018'].isna())\n",
    "#Change in employment\n",
    "X_test['change_jobs'] = (X_test['belbezig2019'].fillna(-1) != X_test['belbezig2018'].fillna(-1)) & (~X_test['belbezig2019'].isna()) & (~X_test['belbezig2018'].isna())\n",
    "#Change in housing\n",
    "X_test['change_house'] = (X_test['woning2019'].fillna(-1) != X_test['woning2018'].fillna(-1)) & (~X_test['woning2019'].isna()) & (~X_test['woning2018'].isna())\n",
    "\n",
    "wave_cols = ['wave2008', 'wave2014', 'wave2019']#\n",
    "X_test[wave_cols] = X_test[wave_cols].fillna(0)\n",
    "X_test[wave_cols] = X_test[wave_cols].astype('object')\n",
    "\n",
    "# make sure missing child birth age is filled with different value\n",
    "child_cols = ['cf19l456', 'cf19l457','cf19l458','cf19l459']\n",
    "X_test[child_cols] = X_test[child_cols].fillna(0)\n",
    "X_test[child_cols] = X_test[child_cols].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b4578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print ROC curve, it tells you how well you can balance false and true positives\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test,\n",
    "    best_model.predict_proba(X_test)[:, 1],\n",
    "    color=\"cornflowerblue\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f52c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Report classification table\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8065995",
   "metadata": {},
   "source": [
    "# rerun model on all given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78862fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train2, y_train2)\n",
    "#best_model = model\n",
    "#not for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a05be",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Dump model (don't change the name)\n",
    "dump(best_model, \"../models/model.joblib\") #allows you to save and load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc9b6f",
   "metadata": {},
   "source": [
    "# For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"datasets/LISS_test.csv\", encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd7c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcomes(df):\n",
    "    \"\"\"Process the input data and write the predictions.\"\"\"\n",
    "    # Dictionary used\n",
    "    dict_kids = {'None': 0, 'One child': 1, 'Two children': 2, 'Three children': 3, 'Four children': 4, 'Five children': 5, 'Six children': 6}\n",
    "    \n",
    "    # Keep \n",
    "    keepcols = ['positie2019','positie2018','gebjaar', 'geslacht','aantalhh2019', 'sted2019', \n",
    "            'nettohh_f2019', 'oplmet2019', 'herkomstgroep2019', 'cf19l128','cf19l129',\n",
    "            'cf19l130', 'cf19l131','cf19l132','woning2019', 'woning2018', \n",
    "            'cf19l456', 'cf19l457', 'cf19l458', 'cf19l459', 'cw19l522', 'cr19l143', \n",
    "            'cf19l483', 'cf19l484', 'cf19l485', 'cf19l486', 'cf19l487', 'cf19l488',\n",
    "           'wave2008', 'wave2014', 'wave2019','aantalki2017','aantalki2018',\n",
    "            'partner2018','partner2019', 'belbezig2019','belbezig2018','ch19l178',\n",
    "           'cp19k118', 'cp19k021', 'cp19k056']\n",
    "    results = df[[\"nomem_encr\"]]\n",
    "    \n",
    "    df = df.loc[:, keepcols]\n",
    "    \n",
    "    df[\"aantalki2018\"] = df[\"aantalki2018\"].map(dict_kids)\n",
    "    df[\"aantalki2017\"] = df[\"aantalki2017\"].map(dict_kids)\n",
    "    #Create new variables about changes in partner status or number of kids (indicators)\n",
    "    df['change_kids'] = (df['aantalki2018'].fillna(-1) != df['aantalki2017'].fillna(-1)) & (~df['aantalki2018'].isna()) & (~df['aantalki2017'].isna())\n",
    "    #Change partner status\n",
    "    df['change_partner'] = (df['partner2019'].fillna(-1) != df['partner2018'].fillna(-1)) & (~df['partner2019'].isna()) & (~df['partner2018'].isna())\n",
    "    #Change in household position\n",
    "    df['change_householdPos'] = (df['positie2019'].fillna(-1) != df['positie2018'].fillna(-1)) & (~df['positie2019'].isna()) & (~df['positie2018'].isna())\n",
    "    #Change in employment\n",
    "    df['change_jobs'] = (df['belbezig2019'].fillna(-1) != df['belbezig2018'].fillna(-1)) & (~df['belbezig2019'].isna()) & (~df['belbezig2018'].isna())\n",
    "    #Change in housing\n",
    "    df['change_house'] = (df['woning2019'].fillna(-1) != df['woning2018'].fillna(-1)) & (~df['woning2019'].isna()) & (~df['woning2018'].isna())\n",
    "\n",
    "    wave_cols = ['wave2008', 'wave2014', 'wave2019']#\n",
    "    df[wave_cols] = df[wave_cols].fillna(0)\n",
    "    df[wave_cols] = df[wave_cols].astype('object')\n",
    "\n",
    "    # make sure missing child birth age is filled with different value\n",
    "    child_cols = ['cf19l456', 'cf19l457','cf19l458','cf19l459']\n",
    "    df[child_cols] = df[child_cols].fillna(0)\n",
    "    df[child_cols] = df[child_cols].astype('object')\n",
    "                            \n",
    "    # Load your trained model from the models directory\n",
    "    model_path = os.path.join(os.path.dirname(__file__), \"..\", \"models\", \"model.joblib\")\n",
    "    model = load(model_path)\n",
    "\n",
    "    # Use your trained model for prediction\n",
    "    results.loc[:, \"prediction\"] = model.predict(df)\n",
    "\n",
    "    #If you use predict_proba to get a probability and a different threshold\n",
    "    #df[\"prediction\"] = (df[\"prediction\"] >= 0.5).astype(int)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = './' #this is not needed outside juypter notebooks\n",
    "predict_outcomes(test_data)#original_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
